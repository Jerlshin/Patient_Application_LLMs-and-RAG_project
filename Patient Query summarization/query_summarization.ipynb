{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import matplotlib.pyplot as plt \n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import nltk \n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446f08e805eb420d87a63c2c7b44f090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12383ab00e7148c382d9c17437cb05d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02506cb9eb6a47f5aa46b28df4c0b749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a584e3fb8fe143e08c537bb97e1bb638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c6a11671f14aec9834248dfd22d8f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8089869b20014783b9622f847b097834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47078165b721435abe73000fc7cf2244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Falconsai/medical_summarization\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Falconsai/medical_summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = \"/home/jerlshin/Documents/My_Work/GenAI_Hackathon_16April2024/Patient_Query_Severity/Patient_Doctor_Severity_Dataset.csv\"\n",
    "\n",
    "dataset = pd.read_csv(path_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Patient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what does abutment of the nerve root mean</td>\n",
       "      <td>hi doctor I am just wondering what is abutting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>every time I eat spicy food I poop blood why</td>\n",
       "      <td>hi doctor I am a 26 year old male I am feet an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>will nano leo give permanent solution for erec...</td>\n",
       "      <td>hello doctor I am 48 years old I am experienci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>will kalarchikai cure multiple ovarian cysts i...</td>\n",
       "      <td>hello doctor I have multiple small cysts in bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I masturbate only by rubbing the tip of the pe...</td>\n",
       "      <td>hi doctor during masturbation I just rub the t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description  \\\n",
       "0          what does abutment of the nerve root mean   \n",
       "1       every time I eat spicy food I poop blood why   \n",
       "2  will nano leo give permanent solution for erec...   \n",
       "3  will kalarchikai cure multiple ovarian cysts i...   \n",
       "4  I masturbate only by rubbing the tip of the pe...   \n",
       "\n",
       "                                             Patient  \n",
       "0  hi doctor I am just wondering what is abutting...  \n",
       "1  hi doctor I am a 26 year old male I am feet an...  \n",
       "2  hello doctor I am 48 years old I am experienci...  \n",
       "3  hello doctor I have multiple small cysts in bo...  \n",
       "4  hi doctor during masturbation I just rub the t...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns = [\"Description\", \"Patient\"]\n",
    "df_org = dataset[selected_columns]\n",
    "\n",
    "df_org.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = df_org.shape[0]\n",
    "\n",
    "# input to the model \n",
    "train_texts = list(df_org.Patient[:SIZE//2])\n",
    "val_texts = list(df_org.Patient[SIZE//2:(3*SIZE)//4 ])\n",
    "test_texts = list(df_org.Patient[(3*SIZE)//4:])\n",
    "\n",
    "# output from the model \n",
    "train_des = list(df_org.Description[:SIZE//2])\n",
    "val_des = list(df_org.Description[SIZE//2:(3*SIZE)//4])\n",
    "test_des = list(df_org.Description[(3*SIZE)//4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIZE == len(train_texts) + len(val_texts) + len(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi doctor I am just wondering what is abutting and abutment of the nerve root means in a back issue please explain what treatment is required for annular bulging and tear'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings  = tokenizer(val_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
    "\n",
    "train_description = tokenizer(train_des, truncation=True, padding=True)\n",
    "val_description = tokenizer(val_des, truncation=True, padding=True)\n",
    "test_description = tokenizer(test_des, truncation=True, padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 12196, 473, 4091, 1182, 1757, 9, 5, 10387, 9749, 1266, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(train_des[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 3592, 3299, 38, 524, 95, 8020, 99, 16, 4091, 1182, 2577, 8, 4091, 1182, 1757, 9, 5, 10387, 9749, 839, 11, 10, 124, 696, 2540, 3922, 99, 1416, 16, 1552, 13, 9915, 8244, 22382, 3923, 8, 7366, 2], [0, 3592, 3299, 38, 524, 10, 973, 76, 793, 2943, 38, 524, 1730, 8, 4877, 6764, 8, 9832, 28080, 2697, 77, 38, 3529, 24042, 689, 38, 36733, 1925, 2128, 77, 38, 33, 10759, 33412, 25, 157, 38, 36733, 10, 410, 828, 9, 1925, 38, 524, 269, 8265, 14, 38, 33, 17735, 1668, 38, 109, 33, 28657, 747, 38, 109, 45, 33, 10, 284, 750, 9, 17735, 1668, 38, 300, 1925, 3457, 626, 94, 363, 2540, 465, 127, 690, 7391, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(train_texts[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, encodings_input, encodings_output):\n",
    "        self.encodings_input = encodings_input  # encoding of the train, val, test \n",
    "        self.encodings_output = encodings_output\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "\n",
    "        \"\"\" Make a dict of the item and the description for the training. for train loop\"\"\"\n",
    "        # return as a tensor \n",
    "        \n",
    "        item = {\n",
    "            \"input_ids\": torch.tensor(self.encodings_input[\"input_ids\"][idx]),\n",
    "            \"attention_mask\": torch.tensor(self.encodings_input[\"input_ids\"][idx]),\n",
    "            \"labels\": torch.tensor(self.encodings_output[\"input_ids\"][idx]),\n",
    "        }\n",
    "\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings_output[\"input_ids\"]) # len of desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = SummarizationDataset(train_encodings, train_description)\n",
    "val_dataloader = SummarizationDataset(val_encodings, val_description)\n",
    "test_dataset = SummarizationDataset(test_encodings, test_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rouge(predictions, references):\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(predictions, references, avg=True)\n",
    "    return scores\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    predictions = pred.predictions\n",
    "    references = pred.label_ids\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_refs = tokenizer.batch_decode(references, skip_special_tokens=True)\n",
    "    rouge_scores = compute_rouge(decoded_preds, decoded_refs)\n",
    "    return rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./QUERY_SUMM_OUTPUT', \n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    num_train_epochs=20,              \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=100,                # setps used for a linear warmup for learning rate \n",
    "    logging_strategy='steps',\n",
    "    logging_dir='./query_summarization',  # tensorboard log dir            \n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\", \n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=training_args,                    \n",
    "    \n",
    "    train_dataset=train_dataloader,     \n",
    "    eval_dataset=val_dataloader,            \n",
    "    \n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForSeq2SeqLM\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TOK_QUERY\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"SUMM_QUERY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"summarization\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text = \"\"\"\n",
    "\n",
    "In this case, the model is processing more tokens (200) than necessary for the short input (47 tokens). To improve efficiency, you can reduce the max_length parameter when calling the pipe function. Here's how you can modify the code:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'ssss'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(text, max_length=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
